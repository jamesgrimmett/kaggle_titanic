{"cells":[{"metadata":{},"cell_type":"markdown","source":["# Titanic: Machine Learning from Disaster\n","\n","**The sinking of the Titanic is one of the most infamous shipwrecks in history.**\n","\n","On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n","\n","While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n","\n","In this notebook,I build a predictive model that answers the question: “what sorts of people were more likely to survive?”, using passenger data such as name, age, gender, socio-economic class, etc."]},{"metadata":{},"cell_type":"markdown","source":["## Overview\n","* Import Libraries\n","* Perform a coarse grid search for the parameter space of several different models\n","* Perform a finer grid search of the best models to finalise model tuning\n","* Combine the best models into an ensemble predictor"]},{"metadata":{},"cell_type":"markdown","source":["## Import libraries\n","---"]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import seaborn as sns # visualisation and plotting tools\n","import scipy\n","import matplotlib.pyplot as plt\n","sns.set(style=\"darkgrid\")"],"execution_count":1,"outputs":[]},{"source":["import data_clean # the cleaning function that was built using the exploration notebook\n","\n","train_df = pd.read_csv('./data/train.csv')#'/kaggle/input/titanic/train.csv')\n","test_df = pd.read_csv('./data/test.csv')#'/kaggle/input/titanic/test.csv')\n","\n","train_df.loc[:,'train'] = 1\n","test_df.loc[:,'train'] = 0\n","test_df.loc[:,'Survived'] = np.nan\n","df = pd.concat((train_df,test_df), ignore_index = True)\n","\n","all_cat = True\n","df = data_clean.clean(df, all_cat = all_cat)\n","df.drop(columns = ['PassengerId'], inplace = True)\n","df.columns"],"cell_type":"code","metadata":{},"execution_count":185,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n","       'Embarked', 'train', 'Ticket_unique', 'Title', 'Num_cabins',\n","       'Cabin_letter'],\n","      dtype='object')"]},"metadata":{},"execution_count":185}]},{"metadata":{"trusted":true},"cell_type":"code","source":["\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.svm import SVC\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.model_selection import cross_val_score\n","\n","# Create the encoder.\n","encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse = False)\n","# Encode the categorical variables and scale the ordinal.\n","encoder.fit(df[df.train == 1].drop(['Survived','train','Age','Fare','SibSp','Parch','Num_cabins'], axis = 1))\n","scaler = StandardScaler()\n","scaler.fit(df[df.train == 1][['Age','Fare','SibSp','Parch','Num_cabins']])\n","\n","# Apply the encoder.\n","X_train_cat = encoder.transform(df[df.train == 1].drop(['Survived','train','Age','Fare','SibSp','Parch','Num_cabins'], axis = 1))\n","X_train_num = scaler.transform(df[df.train == 1][['Age','Fare','SibSp','Parch','Num_cabins']])\n","X_train = np.concatenate([X_train_cat,X_train_num], axis = 1)\n","X_test_cat = encoder.transform(df[df.train == 0].drop(['Survived','train','Age','Fare','SibSp','Parch','Num_cabins'], axis = 1))\n","X_test_num = scaler.transform(df[df.train == 0][['Age','Fare','SibSp','Parch','Num_cabins']])\n","X_test = np.concatenate([X_test_cat,X_test_num], axis = 1)\n","\n","y_train = df[df.train==1].Survived\n","\n","X_train.shape"],"execution_count":186,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(888, 29)"]},"metadata":{},"execution_count":186}]},{"source":["### Coarse grid search\n","Perform a coarse parameter space search for several different models. We will select the top models and perform a finer grid search afterwards"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":187,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'sklearn.linear_model._logistic.LogisticRegression'>\n","<class 'sklearn.linear_model._logistic.LogisticRegression'>\n","<class 'sklearn.svm._classes.SVC'>\n","<class 'sklearn.ensemble._gb.GradientBoostingClassifier'>\n","<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n","<class 'sklearn.neighbors._classification.KNeighborsClassifier'>\n","<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n","<class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>\n"]}],"source":["from sklearn.model_selection import GridSearchCV\n","from sklearn.pipeline import Pipeline\n","\n","cv = 5\n","params = {\n","            'lr_liblin' :\n","            {\n","                'clf': [LogisticRegression(max_iter=1000)],\n","                'clf__solver' : ['liblinear'],\n","                'clf__penalty' : ['l1','l2'],\n","            },\n","            'lr_lbfgs' :\n","            {\n","                'clf': [LogisticRegression(max_iter=1000)],\n","                'clf__solver': ['lbfgs'],\n","                'clf__penalty': ['l2'],\n","            },\n","            'svc' :\n","            {\n","                'clf': [SVC(probability=True)],\n","                'clf__kernel': ['poly', 'rbf', 'sigmoid','linear'],\n","            },\n","            'gbc' :\n","            {\n","                'clf': [GradientBoostingClassifier()],\n","            },\n","            'rfc' :\n","            {\n","                'clf': [RandomForestClassifier()],\n","                'clf__criterion': ['gini','entropy'],\n","            },\n","            'knn' :\n","            {\n","                'clf': [KNeighborsClassifier()],\n","                'clf__weights': ['uniform','distance'],\n","                'clf__n_neighbors': [3, 5, 10, 20],\n","                'clf__p': [1,2]\n","            },\n","            'mlp' :\n","            {\n","                'clf': [MLPClassifier(solver = 'lbfgs')],\n","                'clf__activation': ['identity', 'logistic', 'tanh', 'relu'],\n","            },\n","            'abc' :\n","            {\n","                'clf': [AdaBoostClassifier()]\n","            }\n","        }\n","\n","result=[]\n","best_clfs_coarse = {}\n","for clf_, params_ in params.items():\n","    #classifier\n","    clf = params_['clf'][0]\n","    print(clf.__class__)\n","\n","    #getting arguments by\n","    #popping out classifier\n","    prm_ = dict(params_)\n","    prm_.pop('clf')\n","\n","    #pipeline\n","    steps = [('clf',clf)]\n","\n","    #cross validation using\n","    #Grid Search\n","    grid = GridSearchCV(Pipeline(steps), param_grid=prm_, cv=cv, return_train_score=True)\n","    grid.fit(X_train, y_train)\n","\n","    #storing result\n","    result.append\\\n","    (\n","        {\n","            'classifier': grid.estimator.steps[0][1],\n","            'cv_results': grid.cv_results_\n","        }\n","    )\n","\n","    best_clfs_coarse[clf_] = grid.best_estimator_.steps[0][-1]"]},{"cell_type":"code","execution_count":188,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["    mean_test_score  std_test_score  \\\n","14         0.836749        0.022512   \n","7          0.833352        0.021404   \n","16         0.827772        0.031389   \n","4          0.826585        0.019600   \n","24         0.825475        0.030167   \n","2          0.820974        0.014509   \n","1          0.820974        0.014509   \n","6          0.818676        0.024460   \n","12         0.817609        0.024757   \n","22         0.817552        0.023971   \n","20         0.816467        0.021893   \n","10         0.815349        0.034586   \n","3          0.815330        0.024436   \n","18         0.815330        0.019143   \n","26         0.814220        0.021433   \n","0          0.813090        0.014946   \n","23         0.811960        0.028072   \n","19         0.811960        0.026130   \n","15         0.811960        0.028241   \n","21         0.810849        0.026987   \n","9          0.810804        0.020984   \n","30         0.809763        0.029399   \n","17         0.807478        0.026178   \n","8          0.805174        0.027742   \n","13         0.802984        0.028983   \n","11         0.800717        0.036399   \n","25         0.798476        0.031454   \n","27         0.787209        0.030017   \n","28         0.780404        0.033010   \n","29         0.779242        0.028395   \n","5          0.700425        0.010412   \n","\n","                                               params  \\\n","14  {'clf__n_neighbors': 5, 'clf__p': 1, 'clf__wei...   \n","7                                                  {}   \n","16  {'clf__n_neighbors': 5, 'clf__p': 2, 'clf__wei...   \n","4                              {'clf__kernel': 'rbf'}   \n","24  {'clf__n_neighbors': 20, 'clf__p': 2, 'clf__we...   \n","2      {'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}   \n","1   {'clf__penalty': 'l2', 'clf__solver': 'libline...   \n","6                           {'clf__kernel': 'linear'}   \n","12  {'clf__n_neighbors': 3, 'clf__p': 2, 'clf__wei...   \n","22  {'clf__n_neighbors': 20, 'clf__p': 1, 'clf__we...   \n","20  {'clf__n_neighbors': 10, 'clf__p': 2, 'clf__we...   \n","10  {'clf__n_neighbors': 3, 'clf__p': 1, 'clf__wei...   \n","3                             {'clf__kernel': 'poly'}   \n","18  {'clf__n_neighbors': 10, 'clf__p': 1, 'clf__we...   \n","26                    {'clf__activation': 'identity'}   \n","0   {'clf__penalty': 'l1', 'clf__solver': 'libline...   \n","23  {'clf__n_neighbors': 20, 'clf__p': 1, 'clf__we...   \n","19  {'clf__n_neighbors': 10, 'clf__p': 1, 'clf__we...   \n","15  {'clf__n_neighbors': 5, 'clf__p': 1, 'clf__wei...   \n","21  {'clf__n_neighbors': 10, 'clf__p': 2, 'clf__we...   \n","9                       {'clf__criterion': 'entropy'}   \n","30                                                 {}   \n","17  {'clf__n_neighbors': 5, 'clf__p': 2, 'clf__wei...   \n","8                          {'clf__criterion': 'gini'}   \n","13  {'clf__n_neighbors': 3, 'clf__p': 2, 'clf__wei...   \n","11  {'clf__n_neighbors': 3, 'clf__p': 1, 'clf__wei...   \n","25  {'clf__n_neighbors': 20, 'clf__p': 2, 'clf__we...   \n","27                    {'clf__activation': 'logistic'}   \n","28                        {'clf__activation': 'tanh'}   \n","29                        {'clf__activation': 'relu'}   \n","5                          {'clf__kernel': 'sigmoid'}   \n","\n","                           classifier  \n","14             KNeighborsClassifier()  \n","7        GradientBoostingClassifier()  \n","16             KNeighborsClassifier()  \n","4               SVC(probability=True)  \n","24             KNeighborsClassifier()  \n","2   LogisticRegression(max_iter=1000)  \n","1   LogisticRegression(max_iter=1000)  \n","6               SVC(probability=True)  \n","12             KNeighborsClassifier()  \n","22             KNeighborsClassifier()  \n","20             KNeighborsClassifier()  \n","10             KNeighborsClassifier()  \n","3               SVC(probability=True)  \n","18             KNeighborsClassifier()  \n","26      MLPClassifier(solver='lbfgs')  \n","0   LogisticRegression(max_iter=1000)  \n","23             KNeighborsClassifier()  \n","19             KNeighborsClassifier()  \n","15             KNeighborsClassifier()  \n","21             KNeighborsClassifier()  \n","9            RandomForestClassifier()  \n","30               AdaBoostClassifier()  \n","17             KNeighborsClassifier()  \n","8            RandomForestClassifier()  \n","13             KNeighborsClassifier()  \n","11             KNeighborsClassifier()  \n","25             KNeighborsClassifier()  \n","27      MLPClassifier(solver='lbfgs')  \n","28      MLPClassifier(solver='lbfgs')  \n","29      MLPClassifier(solver='lbfgs')  \n","5               SVC(probability=True)  "],"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>params</th>\n      <th>classifier</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14</th>\n      <td>0.836749</td>\n      <td>0.022512</td>\n      <td>{'clf__n_neighbors': 5, 'clf__p': 1, 'clf__wei...</td>\n      <td>KNeighborsClassifier()</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.833352</td>\n      <td>0.021404</td>\n      <td>{}</td>\n      <td>GradientBoostingClassifier()</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.827772</td>\n      <td>0.031389</td>\n      <td>{'clf__n_neighbors': 5, 'clf__p': 2, 'clf__wei...</td>\n      <td>KNeighborsClassifier()</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.826585</td>\n      <td>0.019600</td>\n      <td>{'clf__kernel': 'rbf'}</td>\n      <td>SVC(probability=True)</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.825475</td>\n      <td>0.030167</td>\n      <td>{'clf__n_neighbors': 20, 'clf__p': 2, 'clf__we...</td>\n      <td>KNeighborsClassifier()</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.820974</td>\n      <td>0.014509</td>\n      <td>{'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}</td>\n      <td>LogisticRegression(max_iter=1000)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.820974</td>\n      <td>0.014509</td>\n      <td>{'clf__penalty': 'l2', 'clf__solver': 'libline...</td>\n      <td>LogisticRegression(max_iter=1000)</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.818676</td>\n      <td>0.024460</td>\n      <td>{'clf__kernel': 'linear'}</td>\n      <td>SVC(probability=True)</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.817609</td>\n      <td>0.024757</td>\n      <td>{'clf__n_neighbors': 3, 'clf__p': 2, 'clf__wei...</td>\n      <td>KNeighborsClassifier()</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.817552</td>\n      <td>0.023971</td>\n      <td>{'clf__n_neighbors': 20, 'clf__p': 1, 'clf__we...</td>\n      <td>KNeighborsClassifier()</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.816467</td>\n      <td>0.021893</td>\n      <td>{'clf__n_neighbors': 10, 'clf__p': 2, 'clf__we...</td>\n      <td>KNeighborsClassifier()</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.815349</td>\n      <td>0.034586</td>\n      <td>{'clf__n_neighbors': 3, 'clf__p': 1, 'clf__wei...</td>\n      <td>KNeighborsClassifier()</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.815330</td>\n      <td>0.024436</td>\n      <td>{'clf__kernel': 'poly'}</td>\n      <td>SVC(probability=True)</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.815330</td>\n      <td>0.019143</td>\n      <td>{'clf__n_neighbors': 10, 'clf__p': 1, 'clf__we...</td>\n      <td>KNeighborsClassifier()</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.814220</td>\n      <td>0.021433</td>\n      <td>{'clf__activation': 'identity'}</td>\n      <td>MLPClassifier(solver='lbfgs')</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.813090</td>\n      <td>0.014946</td>\n      <td>{'clf__penalty': 'l1', 'clf__solver': 'libline...</td>\n      <td>LogisticRegression(max_iter=1000)</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.811960</td>\n      <td>0.028072</td>\n      <td>{'clf__n_neighbors': 20, 'clf__p': 1, 'clf__we...</td>\n      <td>KNeighborsClassifier()</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.811960</td>\n      <td>0.026130</td>\n      <td>{'clf__n_neighbors': 10, 'clf__p': 1, 'clf__we...</td>\n      <td>KNeighborsClassifier()</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.811960</td>\n      <td>0.028241</td>\n      <td>{'clf__n_neighbors': 5, 'clf__p': 1, 'clf__wei...</td>\n      <td>KNeighborsClassifier()</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.810849</td>\n      <td>0.026987</td>\n      <td>{'clf__n_neighbors': 10, 'clf__p': 2, 'clf__we...</td>\n      <td>KNeighborsClassifier()</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.810804</td>\n      <td>0.020984</td>\n      <td>{'clf__criterion': 'entropy'}</td>\n      <td>RandomForestClassifier()</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>0.809763</td>\n      <td>0.029399</td>\n      <td>{}</td>\n      <td>AdaBoostClassifier()</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.807478</td>\n      <td>0.026178</td>\n      <td>{'clf__n_neighbors': 5, 'clf__p': 2, 'clf__wei...</td>\n      <td>KNeighborsClassifier()</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.805174</td>\n      <td>0.027742</td>\n      <td>{'clf__criterion': 'gini'}</td>\n      <td>RandomForestClassifier()</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.802984</td>\n      <td>0.028983</td>\n      <td>{'clf__n_neighbors': 3, 'clf__p': 2, 'clf__wei...</td>\n      <td>KNeighborsClassifier()</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.800717</td>\n      <td>0.036399</td>\n      <td>{'clf__n_neighbors': 3, 'clf__p': 1, 'clf__wei...</td>\n      <td>KNeighborsClassifier()</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.798476</td>\n      <td>0.031454</td>\n      <td>{'clf__n_neighbors': 20, 'clf__p': 2, 'clf__we...</td>\n      <td>KNeighborsClassifier()</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0.787209</td>\n      <td>0.030017</td>\n      <td>{'clf__activation': 'logistic'}</td>\n      <td>MLPClassifier(solver='lbfgs')</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0.780404</td>\n      <td>0.033010</td>\n      <td>{'clf__activation': 'tanh'}</td>\n      <td>MLPClassifier(solver='lbfgs')</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>0.779242</td>\n      <td>0.028395</td>\n      <td>{'clf__activation': 'relu'}</td>\n      <td>MLPClassifier(solver='lbfgs')</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.700425</td>\n      <td>0.010412</td>\n      <td>{'clf__kernel': 'sigmoid'}</td>\n      <td>SVC(probability=True)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":188}],"source":["results = ['mean_test_score',\n","           'mean_train_score',\n","           'std_test_score', \n","           'std_train_score',\n","           'params']\n","df_tuning = pd.DataFrame()\n","for r in result:\n","    df_ = pd.DataFrame(r['cv_results'])[results]\n","    df_['classifier'] = r['classifier']\n","    df_tuning = df_tuning.append(df_, ignore_index = True)\n","df_tuning = df_tuning.sort_values(by = 'mean_test_score', ascending = False)\n","df_tuning[['mean_test_score','std_test_score','params','classifier']]"]},{"cell_type":"code","execution_count":189,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'lr_liblin': LogisticRegression(max_iter=1000, solver='liblinear'),\n"," 'svc': SVC(probability=True),\n"," 'gbc': GradientBoostingClassifier(),\n"," 'rfc': RandomForestClassifier(criterion='entropy'),\n"," 'knn': KNeighborsClassifier(p=1),\n"," 'mlp': MLPClassifier(activation='identity', solver='lbfgs'),\n"," 'abc': AdaBoostClassifier()}"]},"metadata":{},"execution_count":189}],"source":["best_clfs_coarse.pop('lr_lbfgs')\n","best_clfs_coarse"]},{"cell_type":"code","execution_count":190,"metadata":{},"outputs":[],"source":["def param_search(steps, params):\n","    #cross validation using\n","    #Grid Search\n","    grid = GridSearchCV(Pipeline(steps), \n","            param_grid=params, \n","            cv=5, \n","            return_train_score=False, \n","            verbose = True, \n","            n_jobs = 4)\n","    grid.fit(X_train, y_train)\n","\n","    print(grid.best_score_)\n","    print(grid.best_params_)\n","\n","    return grid.best_estimator_.steps[0][-1]"]},{"cell_type":"code","execution_count":191,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 24 candidates, totalling 120 fits\n","0.8367485558306355\n","{'clf__n_neighbors': 5, 'clf__p': 1, 'clf__weights': 'uniform'}\n"]}],"source":["# Tune the KNN\n","\n","params = {\n","    'clf__n_neighbors' : [2,3,4,5,6,10],\n","    'clf__weights': ['uniform','distance'],\n","    'clf__p': [1,2]\n","}\n","\n","best_knn = best_clfs_coarse['knn']\n","#pipeline\n","steps = [('clf', best_knn)]\n","\n","best_knn = param_search(steps, params)"]},{"cell_type":"code","execution_count":192,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 72 candidates, totalling 360 fits\n","0.8299561988192725\n","{'clf__C': 1, 'clf__degree': 2, 'clf__gamma': 'auto'}\n"]}],"source":["# Tune the SVC\n","\n","params = {  \n","        'clf__C' : [1.e-4, 1.e-3, 1.e-2, 1.e-1, 1, 1.e1, 1.e2, 1.e3, 1.e4],\n","        'clf__degree' : [2, 3, 4, 5],\n","        'clf__gamma': ['scale', 'auto'],\n","        }\n","\n","best_svc = best_clfs_coarse['svc']\n","#pipeline\n","steps = [('clf', best_svc)]\n","\n","best_svc = param_search(steps, params)"]},{"cell_type":"code","execution_count":193,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n","0.8412492858503142\n","{'clf__max_depth': 20, 'clf__max_features': 'log2', 'clf__min_samples_leaf': 2, 'clf__n_estimators': 50}\n"]}],"source":["# Tune the RFC\n","\n","params = {  \n","        'clf__max_features' : ['auto', 'sqrt', 'log2'],\n","        'clf__n_estimators' : [10, 50, 100, 1000, 5000],\n","        'clf__max_depth' : [5, 10, 20, 30],\n","        'clf__min_samples_leaf' : [1, 2, 5, 10] \n","        }\n","\n","best_rfc = best_clfs_coarse['rfc']\n","#pipeline\n","steps = [('clf', best_rfc)]\n","\n","best_rfc = param_search(steps, params)"]},{"cell_type":"code","execution_count":198,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 18 candidates, totalling 90 fits\n","0.8209737827715357\n","{'clf__C': 1, 'clf__fit_intercept': True}\n"]}],"source":["# Tune the LR\n","\n","params = {  \n","        'clf__C' : [1.e-4, 1.e-3, 1.e-2, 1.e-1, 1, 1.e1, 1.e2, 1.e3, 1.e4],\n","        'clf__fit_intercept' : [True, False] \n","        }\n","\n","best_lr = best_clfs_coarse['lr_liblin']\n","#pipeline\n","steps = [('clf', best_lr)]\n","\n","best_lr = param_search(steps, params)"]},{"cell_type":"code","execution_count":197,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 20 candidates, totalling 100 fits\n","0.8153494572462388\n","{'clf__alpha': 0.0001, 'clf__learning_rate': 'adaptive', 'clf__max_iter': 200}\n"]}],"source":["# Tune the MLP\n","\n","params = {  \n","        'clf__alpha' : [1.e-4, 1.e-3, 1.e-2, 1.e-1, 1],\n","        'clf__learning_rate'  : ['constant','adaptive'],\n","        'clf__max_iter' : [200,1000],\n","        }\n","\n","best_mlp = best_clfs_coarse['mlp']\n","#pipeline\n","steps = [('clf', best_mlp)]\n","\n","best_mlp = param_search(steps, params)"]},{"cell_type":"code","execution_count":199,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 36 candidates, totalling 180 fits\n","0.833352377324954\n","{'clf__learning_rate': 0.1, 'clf__loss': 'deviance', 'clf__max_depth': 3, 'clf__n_estimators': 100}\n"]}],"source":["# Tune the GBC\n","\n","params = {  \n","        'clf__loss' : ['deviance', 'exponential'],\n","        'clf__learning_rate'  : [0.1, 0.01],\n","        'clf__n_estimators' : [100,500,1000],\n","        'clf__max_depth' : [2,3,5],\n","        }\n","\n","best_gbc = best_clfs_coarse['gbc']\n","#pipeline\n","steps = [('clf', best_gbc)]\n","\n","best_gbc = param_search(steps, params)"]},{"cell_type":"code","execution_count":202,"metadata":{},"outputs":[],"source":["from sklearn.ensemble import VotingClassifier\n","\n","voting_clf_hard = VotingClassifier(estimators = [('knn',best_knn),('svc',best_svc),('rfc',best_rfc),('lr',best_lr),('mlp',best_mlp),('gbc',best_gbc)], voting = 'hard') \n","voting_clf_soft = VotingClassifier(estimators = [('knn',best_knn),('svc',best_svc),('rfc',best_rfc),('lr',best_lr),('mlp',best_mlp),('gbc',best_gbc)], voting = 'soft') "]},{"cell_type":"code","execution_count":203,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["voting_clf_hard : [0.84831461 0.80898876 0.85393258 0.81355932 0.84745763]\nvoting_clf_hard mean : 0.8344505808417445\n"]}],"source":["scores = cross_val_score(voting_clf_hard,X_train,y_train,cv=5)\n","print('voting_clf_hard :', scores)\n","print('voting_clf_hard mean :',np.mean(scores))"]},{"cell_type":"code","execution_count":204,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["voting_clf_soft : [0.84269663 0.80898876 0.8258427  0.81355932 0.85875706]\nvoting_clf_soft mean : 0.8299688948136863\n"]}],"source":["scores = cross_val_score(voting_clf_soft,X_train,y_train,cv=5)\n","print('voting_clf_soft :', scores)\n","print('voting_clf_soft mean :', np.mean(scores))"]},{"cell_type":"code","execution_count":205,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 64 candidates, totalling 320 fits\n","0.8445819843839268\n","{'weights': [2, 2, 1, 1, 1, 1]}\n"]}],"source":["params = {'weights' : [[i,j,k,l,m,n] for i in range(1,3) for j in range(1,3) for k in range(1,3) for l in range(1,3) for m in range(1,3) for n in range(1,3)]}\n","\n","vote_weight = GridSearchCV(voting_clf_hard, param_grid = params, cv = 5, verbose = True, n_jobs = 2)\n","best_clf_weight = vote_weight.fit(X_train,y_train)\n","print(vote_weight.best_score_)\n","print(vote_weight.best_params_)"]},{"cell_type":"code","execution_count":206,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 64 candidates, totalling 320 fits\n","0.836716815844601\n","{'weights': [1, 2, 1, 1, 1, 1]}\n"]}],"source":["params = {'weights' : [[i,j,k,l,m,n] for i in range(1,3) for j in range(1,3) for k in range(1,3) for l in range(1,3) for m in range(1,3) for n in range(1,3)]}\n","\n","vote_weight = GridSearchCV(voting_clf_soft, param_grid = params, cv = 5, verbose = True, n_jobs = 2)\n","best_clf_weight_soft = vote_weight.fit(X_train,y_train)\n","print(vote_weight.best_score_)\n","print(vote_weight.best_params_)"]},{"cell_type":"code","execution_count":207,"metadata":{},"outputs":[],"source":["voting_clf_hard_sub = best_clf_weight.best_estimator_.predict(X_test).astype(int)\n","voting_clf_soft_sub = best_clf_weight_soft.best_estimator_.predict(X_test).astype(int)\n","rfc_sub = best_rfc.predict(X_test).astype(int)"]},{"cell_type":"code","execution_count":26,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":["418\n418\n"]}],"source":["#%debug\n","import data_clean\n","test_df = pd.read_csv('./data/test.csv')\n","print(len(test_df))\n","test_df = data_clean.clean(test_df, all_cat == True)\n","print(len(test_df))"]},{"cell_type":"code","execution_count":212,"metadata":{},"outputs":[],"source":["final_data_hard_vote = {'PassengerId': test_df.PassengerId, 'Survived': voting_clf_hard_sub}\n","submission_hard_vote = pd.DataFrame(data=final_data_hard_vote)\n","submission_hard_vote.to_csv('submission_voting_hard_clf.csv', index =False)"]},{"cell_type":"code","execution_count":213,"metadata":{},"outputs":[],"source":["final_data_soft_vote = {'PassengerId': test_df.PassengerId, 'Survived': voting_clf_soft_sub}\n","submission_soft_vote = pd.DataFrame(data=final_data_soft_vote)\n","submission_soft_vote.to_csv('submission_voting_soft_clf.csv', index =False)"]},{"cell_type":"code","execution_count":214,"metadata":{},"outputs":[],"source":["final_data_rfc = {'PassengerId': test_df.PassengerId, 'Survived': rfc_sub}\n","submission_rfc = pd.DataFrame(data=final_data_rfc)\n","submission_rfc.to_csv('submission_rfc_clf.csv', index =False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.8.5-final","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}